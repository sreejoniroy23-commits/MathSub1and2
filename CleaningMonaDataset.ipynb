{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b10ee84",
   "metadata": {},
   "source": [
    "Sreejoni Roy\n",
    "*Cleaning Mona’s Dataset: Country Normalization and Likert Conversion*\n",
    "\n",
    "I first cleaned Mona’s raw survey dataset to make sure the data was consistent and ready for modeling. The first part of the cleaning focused on standardizing the country field, because people wrote “Netherlands” in many different ways (e.g., Netherlands, Nederland, NL, Holland, The Netherlands, and even versions with typos). To avoid mismatches later on, I created a simple normalisation function that converts all of these variants into a single label: “netherlands”.\n",
    "\n",
    "After normalising the country values, I filtered the dataset so that only participants located in the Netherlands were kept. \n",
    "\n",
    "Next, I worked on the survey’s Likert-scale questions. These items were answered using text labels such as Strongly disagree, Disagree, Neutral, Agree, and Strongly agree as well as other worded scales. I mapped the five categories to a numeric scale from 1 to 5, keeping the original text responses intact but adding new columns with the numeric equivalents (using a “_num” suffix).\n",
    "Detecting the Likert questions was done automatically by scanning for common response words, and then applying the numeric mapping. \n",
    "\n",
    "Overall, these steps produced a clean, consistent dataset containing only Dutch respondents and numeric versions of all Likert-scale variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Mona Dataset.csv\")\n",
    "#reading mona dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df049c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (225, 57)\n",
      "First 10 columns:\n",
      " ['ID', 'Start time', 'Completion time', 'Email', 'Name', 'Last modified time', 'Please share your email address', 'In which country are you located?', 'What is your country of origin?', \"Which description fits your parents' country of origin the best?\"]\n"
     ]
    }
   ],
   "source": [
    "#checking the shape and columns\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"First 10 columns:\\n\", list(df.columns)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d017680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the country of origin field and remove anyone whose origin is not the Netherlands\n",
    "\n",
    "#picking the correct column/question\n",
    "ORIGIN_COL = \"What is your country of origin?\"\n",
    "\n",
    "def normalize_country(x):\n",
    "    \n",
    "    # if a value is missing, return it to NaN so that I can drop it later\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    # basic lowercasing and trimming (lowercasing so it's easier)\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    # all the common ways people typed Netherlands (no uppercase cause that was fixed in the code above.)\n",
    "    direct_map = {\n",
    "        \"the netherlands\": \"netherlands\",\n",
    "        \"netherlands\": \"netherlands\",\n",
    "        \"nederland\": \"netherlands\",\n",
    "        \"holland\": \"netherlands\",\n",
    "        \"nl\": \"netherlands\",\n",
    "        \"the netherland\": \"netherlands\",\n",
    "    }\n",
    "\n",
    "    # this checks if the cleaned string matches the list directly\n",
    "    if s in direct_map:\n",
    "        return direct_map[s]\n",
    "    \n",
    "    # removing any punctuation and keep only letters/numbers/spaces\n",
    "    s_simple = \"\".join(ch for ch in s if ch.isalnum() or ch.isspace()).strip()\n",
    "\n",
    "    # checking again using the simplified version\n",
    "    if s_simple in direct_map:\n",
    "        return direct_map[s_simple]\n",
    "\n",
    "    # finding things like \"netherlands amsterdam\"\n",
    "    if \"netherland\" in s_simple or \"nederland\" in s_simple:\n",
    "        return \"netherlands\"\n",
    "    \n",
    "    # returning the cleaned value so I can inspect it later\n",
    "    return s_simple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386d18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cleaning the origin column\n",
    "# I'm adding a new column called \"origin_norm\" which stores the cleaned and normalized version of each person’s origin.\n",
    "df[\"origin_norm\"] = df[ORIGIN_COL].apply(normalize_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b4b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any missing country-of-origin values\n",
    "\n",
    "df_clean_origin = df.dropna(subset=[\"origin_norm\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314587f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  keeping only the respondents whose origin is Netherlands, therefore removing non-netherlands people\n",
    "\n",
    "df_origin_nl = df_clean_origin[df_clean_origin[\"origin_norm\"] == \"netherlands\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d8db411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows kept (Netherlands origin only): 132 out of 225\n",
      "\n",
      "Unique cleaned origin values still present:\n",
      "origin_norm\n",
      "netherlands    132\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows kept (Netherlands origin only):\", \n",
    "      df_origin_nl.shape[0], \"out of\", df.shape[0])\n",
    "\n",
    "print(\"\\nUnique cleaned origin values still present:\")\n",
    "print(df_origin_nl[\"origin_norm\"].value_counts())\n",
    "\n",
    "#showing how many rows are remaning after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe09670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likert-style scales to numbers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "likert_df = df_origin_nl.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c9e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cleaning each cell \n",
    "def _clean_cell(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    s = s.replace(\"\\u00a0\", \" \") \n",
    "    s = \" \".join(s.split())       # removing multiple spaces\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the scales \n",
    "\n",
    "# 1) Agreement scale (5-points)\n",
    "agree_options = [\n",
    "    \"strongly disagree\",\n",
    "    \"disagree\",\n",
    "    \"neutral\",\n",
    "    \"agree\",\n",
    "    \"strongly agree\",\n",
    "]\n",
    "agree_map = {opt: i+1 for i, opt in enumerate(agree_options)}  # 1..5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c65499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Frequency scale (5-points) \n",
    "freq_options = [\n",
    "    \"never\",\n",
    "    \"rarely\",\n",
    "    \"sometimes\",\n",
    "    \"often\",\n",
    "    \"always\",\n",
    "]\n",
    "freq_map = {\n",
    "    \"never\": 1,\n",
    "    \"rarely\": 2,\n",
    "    \"sometimes\": 3,\n",
    "    \"often\": 4,\n",
    "    \"always\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd5b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Duration/Recency scale (5-points) —  \"I don't know\" is NaN\n",
    "dur_options = [\n",
    "    \"less than a day\",\n",
    "    \"1-2 days\",\n",
    "    \"3-5 days\",\n",
    "    \"about a week\",\n",
    "    \"more than a week\",\n",
    "    \"i don't know\",\n",
    "]\n",
    "dur_map = {\n",
    "    \"less than a day\": 1,\n",
    "    \"1-2 days\": 2,\n",
    "    \"3-5 days\": 3,\n",
    "    \"about a week\": 4,\n",
    "    \"more than a week\": 5,\n",
    "    \"i don't know\": np.nan,   # treat it as missing\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae6e7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    " #4) Exposure scale (4-points)\n",
    "expose_options = [\n",
    "    \"no, never\",\n",
    "    \"i've heard of it but haven't seen it\",\n",
    "    \"yes, a few times\",\n",
    "    \"yes, many times\",\n",
    "]\n",
    "expose_map = {\n",
    "    \"no, never\": 1,\n",
    "    \"i've heard of it but haven't seen it\": 2,\n",
    "    \"yes, a few times\": 3,\n",
    "    \"yes, many times\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd42546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packaging the scales so that I can loop \n",
    "scales = [\n",
    "    (\"agreement_5\", set(agree_options), agree_map),\n",
    "    (\"frequency_5\", set(freq_options),  freq_map),\n",
    "    (\"duration_5\",  set(dur_options),   dur_map),\n",
    "    (\"exposure_4\",  set(expose_options), expose_map),\n",
    "]\n",
    "\n",
    "mapped_cols = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "865d047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out and mapping each column if its unique cleaned values are a subset of one of the known scales\n",
    "for col in likert_df.columns:\n",
    "                                       #  ignoring NaN\n",
    "    uniq = (\n",
    "        likert_df[col]\n",
    "        .dropna()\n",
    "        .map(_clean_cell)\n",
    "        .dropna()\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "    if len(uniq) == 0:\n",
    "        continue\n",
    "\n",
    "    uniq_set = set(uniq)\n",
    "\n",
    "    # trying out each scale\n",
    "    for scale_name, opt_set, opt_map in scales:\n",
    "           # allowing the columns to contain a subset of the options \n",
    "        if uniq_set.issubset(opt_set):\n",
    "            num_col = col + \"_num\"\n",
    "            likert_df[num_col] = likert_df[col].map(_clean_cell).map(opt_map)\n",
    "            mapped_cols.append((col, scale_name))\n",
    "            break  # stopping at first matching scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc7c682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped columns (original -> scale):\n",
      " - I use social media  ->  frequency_5\n",
      " - I think social media is fair  ->  agreement_5\n",
      " - I see repeated topics on my feed  ->  agreement_5\n",
      " - I see different opinions on the same topic  ->  frequency_5\n",
      " - My feed varies within my social circle   ->  agreement_5\n",
      " - I often notice that someone didn't know about a trend, which I thought everybody had seen   ->  agreement_5\n",
      " - It is harder for me to take part in a discussion regarding a topic when I have not seen the topic on my feed yet   ->  agreement_5\n",
      " - I notice that people mostly agree with what's trending, they rarely add their own personal views - add happens to options  ->  frequency_5\n",
      " - A topic/trend usually stays on my feed for ...  ->  duration_5\n",
      " - When I see a post and open the comments, the top comments reflect what I am already thinking about  ->  frequency_5\n",
      " - I scroll through the comments to see if someone has mentioned what I am thinking about  ->  frequency_5\n",
      " - I notice a lot of agreement with the content in the comments  ->  agreement_5\n",
      " - I tend to comment on content I disagree with  ->  agreement_5\n",
      " - I often see new ideas and topics on my feed   ->  agreement_5\n",
      " - When I see a new topic on my feed, I tend to scroll away  ->  agreement_5\n",
      " - My feed does not show information that others could be seeing  ->  agreement_5\n",
      " - I feel like my content gets the same number of views as content from others  ->  agreement_5\n",
      " - I feel like my content gets the same number of views as content from others with a different background  (e.g., race, gender, age) than mine  ->  agreement_5\n",
      " - I think content from certain groups of people is prioritized over other groups   ->  agreement_5\n",
      " - I am informed that my feed is shaped by personal information like my age, gender or location - transparency   ->  agreement_5\n",
      " - I would feel comfortable swapping feeds with someone from a different background than mine (e.g., age, race, beliefs)  ->  agreement_5\n",
      " - If everyone got my feed, I think some people might be shocked by the content they see  ->  agreement_5\n",
      " - I would be okay seeing less of my favorite type of content if it meant more equal exposure for everyone  ->  agreement_5\n",
      " - If I had to exchange feeds with someone really different from me, I don't think I would like what I would see  ->  agreement_5\n",
      " - When I post about topics like politics or social issues, it feels like my voice can be seen and heard  ->  agreement_5\n",
      " - I feel like the algorithm shapes what political topics I get to see  ->  agreement_5\n",
      " - I rarely see posts that challenge my own political views unless I search for them  ->  agreement_5\n",
      " - I've seen creators mention that their political-related content was shadowbanned   ->  exposure_4\n",
      " - I feel I am in control of my feed  ->  agreement_5\n",
      " - I can influence the type of content I get on my feed  ->  agreement_5\n",
      " - The algorithm decides what I watch  ->  agreement_5\n",
      " - I scroll through recommendations  ->  frequency_5\n",
      " - I end up watching videos I didn't intend to watch  ->  frequency_5\n",
      " - Scrolling feels like a habit rather than a conscious choice  ->  agreement_5\n",
      " - I sometimes spend more time scrolling than I had planned  ->  agreement_5\n",
      " - I feel like my feed shows me a good mix of topics to stay informed (e.g., news, social issues, or different opinons)  ->  agreement_5\n",
      " - I believe that the algorithm hides certain social or political views  ->  agreement_5\n",
      " - I feel like I have a fair chance to be seen/heard  ->  agreement_5\n",
      " - I trust the algorithm to recommend me content fairly  ->  agreement_5\n",
      " - I think social media is fair2  ->  agreement_5\n",
      "\n",
      "I use social media_num value counts:\n",
      "I use social media_num\n",
      "5    63\n",
      "4    53\n",
      "3    14\n",
      "2     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "I think social media is fair_num value counts:\n",
      "I think social media is fair_num\n",
      "3    61\n",
      "2    38\n",
      "4    25\n",
      "1     5\n",
      "5     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "I see repeated topics on my feed_num value counts:\n",
      "I see repeated topics on my feed_num\n",
      "4    84\n",
      "5    33\n",
      "3    14\n",
      "1     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# seeing what i got mapped and how\n",
    "print(\"Mapped columns (original -> scale):\")\n",
    "for c, s in mapped_cols:\n",
    "    print(f\" - {c}  ->  {s}\")\n",
    "\n",
    "# seeing the counts for a couple of mapped columns\n",
    "for c, _ in mapped_cols[:3]:\n",
    "    print(f\"\\n{c}_num value counts:\")\n",
    "    print(likert_df[c + \"_num\"].value_counts(dropna=False))\n",
    "\n",
    "# putting it back to the main dataframe \n",
    "df_origin_nl = likert_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
