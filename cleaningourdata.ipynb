{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c62b11",
   "metadata": {},
   "source": [
    "Sreejoni Roy\n",
    "**Cleaning our datasets**\n",
    "\n",
    "For this sub-assignment, I am working with survey data that was originally created by Mona Zakkour for her bachelor thesis. Mona developed a theoretical framework and designed a questionnaire based on it. She collected her data in the Netherlands using Google Forms.\n",
    "\n",
    "As part of the assignment, our group had to roll out the same survey individually to at least 20 participants in one assigned country: Greece, Germany, or Spain. Because of this, we now have multiple separate datasets; The four datasets I am working with are:\n",
    "\n",
    "-Two datasets from Spain\n",
    "\n",
    "-One dataset from Greece\n",
    "\n",
    "-One dataset from Germany\n",
    "\n",
    "These files were exported as CSV files from Google Forms, which means the structure is mostly the same, but the responses contain differences such as:\n",
    "\n",
    "-variations in language (e.g., España, spain, Spain)\n",
    "\n",
    "-different capitalisation and spacing\n",
    "\n",
    "-inconsistent country names across datasets\n",
    "\n",
    "-extra spaces or symbols inside text entries\n",
    "\n",
    "Before I can merge everything into one complete dataset for analysis, I need to clean each file individually.\n",
    "\n",
    "This includes:\n",
    "\n",
    "-removing accidental spaces and formatting issues\n",
    "\n",
    "-standardising country names (e.g., España → Spain, Deutschland → Germany)\n",
    "\n",
    "-converting missing values into a consistent format\n",
    "\n",
    "-making sure all columns are aligned so the files can be merged properly\n",
    "\n",
    "Once all four datasets are cleaned, I will merge them into one combined dataset.\n",
    "This final dataset will allow us to run the statistical tests required for the assignment (Mona’s original Netherlands dataset + Greece + Spain + Germany).\n",
    "\n",
    "This cleaning and merging step is essential because combining uncleaned data from different countries would create inconsistencies, reduce data quality, and affect the reliability of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9638fb1",
   "metadata": {},
   "source": [
    "**Spain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the two Spain Datasets \n",
    "# In this code I am cleaning the two Spain survey files.\n",
    "# To fix spelling differences in country names and remove extra spaces.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe89975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I put all files in the same folder so I just point to the current directory.\n",
    "DATA_PATH = Path(\".\")\n",
    "\n",
    "# These are the two Spain files .\n",
    "SPAIN1 = DATA_PATH / \"spain1dataset.csv\"\n",
    "SPAIN2 = DATA_PATH / \"spain2dataset.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e86ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function tries to read a CSV safely even when the file has weird or mixed encodings.\n",
    "# Some CSV files exported from Qualtrics, Excel, or Google Sheets do not read properly with\n",
    "# the standard UTF-8 encoding. They might contain hidden characters (like BOM markers) or\n",
    "# use different text encodings depending on the user's system.\n",
    "def safe_read_csv(path):\n",
    "\n",
    "    # I looped through a small list of common encodings that usually cause problems.\n",
    "    # \"utf-8\" is the normal one,\n",
    "    # \"utf-8-sig\" handles files that start with a BOM,\n",
    "    # \"latin-1\" and \"cp1252\" are common in European Windows systems.\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"latin-1\", \"cp1252\"]:\n",
    "        try:\n",
    "            # reading the file with the current encoding.\n",
    "            # If this works, the function returns the DataFrame immediately.\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except:\n",
    "            # If this fails, then let it go\n",
    "            pass\n",
    "\n",
    "    #default\n",
    "    return pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f30fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code helps me compare the text regardless of accents or capital letters.\n",
    "# For example \"España\", \"espana\", \"ESPAÑA\" should all detect as the same thing.\n",
    "def normalize_string(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = \" \".join(s.split()).strip()     # remove weird spacing\n",
    "    s = s.lower()                       # make everything lowercase\n",
    "    # remove accents so \"España\" becomes \"espana\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fde180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#country names and possible typos\n",
    "COUNTRY_MAP = {\n",
    "    \"spain\": \"Spain\",\n",
    "    \"espana\": \"Spain\",\n",
    "    \"es\": \"Spain\",\n",
    "\n",
    "    \"netherlands\": \"Netherlands\",\n",
    "    \"the netherlands\": \"Netherlands\",\n",
    "    \"nederland\": \"Netherlands\",\n",
    "    \"holland\": \"Netherlands\",\n",
    "\n",
    "    \"argentina\": \"Argentina\",\n",
    "\n",
    "    \"\": np.nan,\n",
    "    \"nan\": np.nan\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35651a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cleans all text columns.\n",
    "# removing leading/trailing spaces that people often leave out.\n",
    "def clean_text_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]   # clean column names\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].apply(lambda x: \" \".join(x.split()).strip()\n",
    "                                if isinstance(x, str) else x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9742861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This coding fixes all the country columns.\n",
    "# I looked for any column that contained the word \"country\".\n",
    "def standardize_country_columns(df):\n",
    "    df = df.copy()\n",
    "    country_cols = [c for c in df.columns if \"country\" in c.lower()]\n",
    "\n",
    "    for col in country_cols:\n",
    "        # I turned the column values into \"normalized keys\"\n",
    "        # so I could map them properly to the COUNTRY_MAP\n",
    "        keys = df[col].apply(lambda x: normalize_string(x) if not pd.isna(x) else x)\n",
    "\n",
    "        # If the normalized version is in the dictionary, use the official version.\n",
    "        # If not, keep the original.\n",
    "        mapped_values = keys.map(COUNTRY_MAP)\n",
    "        df[col] = np.where(mapped_values.notna(), mapped_values, df[col])\n",
    "\n",
    "        #second check for very common mistakes like \"Spain \" or \"spain\".\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: \"Spain\" if normalize_string(x) == \"spain\"\n",
    "            else (\"Netherlands\" if normalize_string(x) in\n",
    "                  {\"netherlands\", \"the netherlands\", \"nederland\", \"holland\"}\n",
    "                  else (\"Argentina\" if normalize_string(x) == \"argentina\"\n",
    "                        else (np.nan if normalize_string(x) in {\"\", \"nan\"} else x)))\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_before_after_uniques(before, after, title):\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    country_cols = [c for c in before.columns if \"country\" in c.lower()]\n",
    "    for col in country_cols:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(\"Before:\", sorted(before[col].astype(str).fillna(\"NaN\").unique().tolist()))\n",
    "        print(\"After: \", sorted(after[col].astype(str).fillna(\"NaN\").unique().tolist()))\n",
    "\n",
    "#to see a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda63ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading both the Spain files\n",
    "spain1_raw = safe_read_csv(SPAIN1)\n",
    "spain2_raw = safe_read_csv(SPAIN2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29da8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the basic text formatting\n",
    "spain1_step1 = clean_text_columns(spain1_raw)\n",
    "spain2_step1 = clean_text_columns(spain2_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065032d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing the country names\n",
    "spain1_clean = standardize_country_columns(spain1_step1)\n",
    "spain2_clean = standardize_country_columns(spain2_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c656197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SPAIN 1 =====\n",
      "\n",
      "Column: In which country are you located?\n",
      "Before: ['España', 'Spain', 'Spain ', 'spain']\n",
      "After:  ['Spain']\n",
      "\n",
      "Column: What is your country of origin?\n",
      "Before: ['Argentina', 'España', 'Spain', 'Spain ', 'spain']\n",
      "After:  ['Argentina', 'Spain']\n",
      "\n",
      "Column: Which description fits your parents' country of origin the best?\n",
      "Before: ['Both parents are from outside the EU', 'Both parents are from the EU']\n",
      "After:  ['Both parents are from outside the EU', 'Both parents are from the EU']\n",
      "\n",
      "===== SPAIN 2 =====\n",
      "\n",
      "Column: In which country are you located?\n",
      "Before: ['España', 'Netherlands', 'Netherlands ', 'Spain', 'Spain ', 'nan', 'spain']\n",
      "After:  ['Netherlands', 'Spain', 'nan']\n",
      "\n",
      "Column: What is your country of origin?\n",
      "Before: ['España', 'Spain', 'nan', 'spain']\n",
      "After:  ['Spain', 'nan']\n",
      "\n",
      "Column: Which description fits your parents' country of origin the best?\n",
      "Before: ['Both parents are from the EU', 'One parent is from the EU and one parent is outside of the EU', 'nan']\n",
      "After:  ['Both parents are from the EU', 'One parent is from the EU and one parent is outside of the EU', 'nan']\n"
     ]
    }
   ],
   "source": [
    "# printing the before/after so I can visually confirm everything\n",
    "show_before_after_uniques(spain1_raw, spain1_clean, \"SPAIN 1\")\n",
    "show_before_after_uniques(spain2_raw, spain2_clean, \"SPAIN 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a07bb9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved cleaned files: spain1dataset_clean.csv and spain2dataset_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# saving both cleaned versions\n",
    "spain1_clean.to_csv(\"spain1dataset_clean.csv\", index=False)\n",
    "spain2_clean.to_csv(\"spain2dataset_clean.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved cleaned files: spain1dataset_clean.csv and spain2dataset_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05e445",
   "metadata": {},
   "source": [
    "**Greece**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073038c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c7f13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where everything is saved\n",
    "DATA_PATH = Path(\".\")\n",
    "GREECE = DATA_PATH / \"greekdataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaf97400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read_csv(path):\n",
    "    # I put in Greek encodings (cp1253, iso-8859-7).\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"cp1253\", \"iso-8859-7\", \"latin-1\", \"cp1252\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53479612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code normalises text so comparisons are easier.\n",
    "# I removed spacing and accents, but I kept the original letters (so Greek stays Greek).\n",
    "def normalize_basic(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    # removed extra internal spaces and trim\n",
    "    s = \" \".join(s.split()).strip().lower()\n",
    "    # removed diacritics (accents) but keep letters \n",
    "    nf = unicodedata.normalize(\"NFKD\", s)\n",
    "    s_no_marks = \"\".join(ch for ch in nf if unicodedata.category(ch) != \"Mn\")\n",
    "    return s_no_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4095fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY_MAP = {\n",
    "    # Greece variants\n",
    "    \"ελλαδα\": \"Greece\",   # Ελλάδα without accent after normalize_basic\n",
    "    \"ελλας\": \"Greece\",    # Ελλας (Hellas in Greek letters)\n",
    "    \"greece\": \"Greece\",\n",
    "    \"gr\": \"Greece\",\n",
    "    \"ellada\": \"Greece\",   \n",
    "    \"hellas\": \"Greece\",\n",
    "\n",
    "    # Also includes other countries just in case they appear in these columns\n",
    "    \"germany\": \"Germany\",\n",
    "    \"deutschland\": \"Germany\",\n",
    "    \"alemania\": \"Germany\",\n",
    "\n",
    "    \"spain\": \"Spain\",\n",
    "    \"espana\": \"Spain\",\n",
    "\n",
    "    \"netherlands\": \"Netherlands\",\n",
    "    \"the netherlands\": \"Netherlands\",\n",
    "    \"nederland\": \"Netherlands\",\n",
    "    \"holland\": \"Netherlands\",\n",
    "\n",
    "    # missed data will become real NaN\n",
    "    \"\": np.nan,\n",
    "    \"nan\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9de6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I cleanned the text in the whole table:\n",
    "# stripped the spaces from column names\n",
    "# trimmed the spaces inside text cells\n",
    "def clean_text_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].apply(lambda x: \" \".join(x.split()).strip()\n",
    "                                if isinstance(x, str) else x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4516a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing any column that looks like it stores a country.\n",
    "# matching by normalising the text and looking it up in COUNTRY_MAP.\n",
    "def standardize_country_columns(df):\n",
    "    df = df.copy()\n",
    "    country_cols = [c for c in df.columns if \"country\" in c.lower()]\n",
    "\n",
    "    for col in country_cols:\n",
    "        # creating a \"key\" version of each value for mapping\n",
    "        keys = df[col].apply(lambda x: normalize_basic(x) if not pd.isna(x) else x)\n",
    "        mapped = keys.map(COUNTRY_MAP)\n",
    "\n",
    "        # if a canonical label is found, the code will use it. Otherwise keep it the original.\n",
    "        df[col] = np.where(mapped.notna(), mapped, df[col])\n",
    "\n",
    "        # a second pass to catch super-common loose cases\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: (\n",
    "                \"Greece\" if normalize_basic(x) in {\"ελλαδα\",\"ελλας\",\"greece\",\"ellada\",\"hellas\",\"gr\"}\n",
    "                else (\"Germany\" if normalize_basic(x) in {\"germany\",\"deutschland\",\"alemania\"}\n",
    "                else (\"Spain\" if normalize_basic(x) in {\"spain\",\"espana\"}\n",
    "                else (\"Netherlands\" if normalize_basic(x) in {\"netherlands\",\"the netherlands\",\"nederland\",\"holland\"}\n",
    "                else (np.nan if normalize_basic(x) in {\"\", \"nan\"} else x))))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b23ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the unique values before and after for the country columns.\n",
    "def show_before_after_uniques(before, after, title):\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    country_cols = [c for c in before.columns if \"country\" in c.lower()]\n",
    "    for col in country_cols:\n",
    "        b = sorted(pd.Series(before[col].astype(str).fillna(\"NaN\").unique()).tolist())\n",
    "        a = sorted(pd.Series(after[col].astype(str).fillna(\"NaN\").unique()).tolist())\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(\"Before:\", b)\n",
    "        print(\"After: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ab24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Greece file safely\n",
    "gr_raw = safe_read_csv(GREECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd8d7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning general text issues first (spaces, weird formatting)\n",
    "gr_step1 = clean_text_columns(gr_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ced19d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing country names (Ελλάδα → Greece etc.)\n",
    "gr_clean = standardize_country_columns(gr_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43a14a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== GREECE =====\n",
      "\n",
      "Column: In which country are you located?\n",
      "Before: ['Amsterdam ', 'Canada', 'Canada ', 'France', 'Greece', 'Greece ', 'Netherlands ', 'The Netherlands', 'The Netherlands ', 'UK', 'cairo']\n",
      "After:  ['Amsterdam', 'Canada', 'France', 'Greece', 'Netherlands', 'UK', 'cairo']\n",
      "\n",
      "Column: What is your country of origin?\n",
      "Before: ['Canada', 'China ', 'Egypt ', 'Greece', 'Greece ', 'Greek']\n",
      "After:  ['Canada', 'China', 'Egypt', 'Greece', 'Greek']\n",
      "\n",
      "Column: Which description fits your parents' country of origin the best?\n",
      "Before: ['Both parents are born and brought up in the Greece', 'Both parents are from outside the EU', 'Both parents are from the EU']\n",
      "After:  ['Both parents are born and brought up in the Greece', 'Both parents are from outside the EU', 'Both parents are from the EU']\n"
     ]
    }
   ],
   "source": [
    "# Showing the change in country columns\n",
    "show_before_after_uniques(gr_raw, gr_clean, \"GREECE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de837dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: greekdataset_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# saving the cleaned dataset\n",
    "gr_clean.to_csv(\"greekdataset_clean.csv\", index=False)\n",
    "print(\"\\nSaved: greekdataset_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1759b7",
   "metadata": {},
   "source": [
    "**Germany**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a989e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6853e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\".\")\n",
    "GERMANY = DATA_PATH / \"Germany dataset.csv\"   # original file has a space in the name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e41d4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding for google form errors\n",
    "def safe_read_csv(path):\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"latin-1\", \"cp1252\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # If everything else fails,  default will work\n",
    "    return pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "112db715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  normalizing text so comparisons are easier.\n",
    "# This code removes the extra spaces, lowers case, and strips accents.\n",
    "def normalize_basic(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = \" \".join(s.split()).strip().lower()\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40b1c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY_MAP = {\n",
    "    # Germany variants\n",
    "    \"germany\": \"Germany\",\n",
    "    \"deutschland\": \"Germany\",\n",
    "    \"ger\": \"Germany\",\n",
    "    \"de\": \"Germany\",\n",
    "    \"alemania\": \"Germany\",\n",
    "\n",
    "    # Spain variants (appears in origin/parents columns sometimes)\n",
    "    \"spain\": \"Spain\",\n",
    "    \"espana\": \"Spain\",\n",
    "\n",
    "    # Greece variants \n",
    "    \"greece\": \"Greece\",\n",
    "    \"ellada\": \"Greece\",\n",
    "    \"hellas\": \"Greece\",\n",
    "    \"gr\": \"Greece\",\n",
    "\n",
    "    # Netherlands (sometimes appears in 'located in')\n",
    "    \"netherlands\": \"Netherlands\",\n",
    "    \"the netherlands\": \"Netherlands\",\n",
    "    \"nederland\": \"Netherlands\",\n",
    "    \"holland\": \"Netherlands\",\n",
    "\n",
    "    # missing info will turn into real NaN\n",
    "    \"\": np.nan,\n",
    "    \"nan\": np.nan,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b479ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cleaning the column names and trim the spaces inside every text cell.\n",
    "def clean_text_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = df[col].apply(lambda x: \" \".join(x.split()).strip()\n",
    "                                if isinstance(x, str) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33ac00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing any column that looks like a country column.\n",
    "# I searched for 'country' in the column name to keep this flexible.\n",
    "def standardize_country_columns(df):\n",
    "    df = df.copy()\n",
    "    country_cols = [c for c in df.columns if \"country\" in c.lower()]\n",
    "\n",
    "    for col in country_cols:\n",
    "        # Creating normalized keys for mapping\n",
    "        keys = df[col].apply(lambda x: normalize_basic(x) if not pd.isna(x) else x)\n",
    "        mapped = keys.map(COUNTRY_MAP)\n",
    "\n",
    "        # If there is a mapped value, this code will use it; otherwise it will keep the original.\n",
    "        df[col] = np.where(mapped.notna(), mapped, df[col])\n",
    "\n",
    "        #  catching very common loose cases (e.g., \"Germany \" or \"ger\")\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: (\n",
    "                \"Germany\" if normalize_basic(x) in {\"germany\",\"deutschland\",\"ger\",\"de\",\"alemania\"}\n",
    "                else (\"Spain\" if normalize_basic(x) in {\"spain\",\"espana\"}\n",
    "                else (\"Greece\" if normalize_basic(x) in {\"greece\",\"ellada\",\"hellas\",\"gr\"}\n",
    "                else (\"Netherlands\" if normalize_basic(x) in {\"netherlands\",\"the netherlands\",\"nederland\",\"holland\"}\n",
    "                else (np.nan if normalize_basic(x) in {\"\", \"nan\"} else x))))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d1126cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before and after sample show\n",
    "def show_before_after_uniques(before, after, title):\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    country_cols = [c for c in before.columns if \"country\" in c.lower()]\n",
    "    for col in country_cols:\n",
    "        b = sorted(pd.Series(before[col].astype(str).fillna(\"NaN\").unique()).tolist())\n",
    "        a = sorted(pd.Series(after[col].astype(str).fillna(\"NaN\").unique()).tolist())\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(\"Before:\", b)\n",
    "        print(\"After: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "722a989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_raw = safe_read_csv(GERMANY) #loading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f1c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the general text issues first \n",
    "de_step1 = clean_text_columns(de_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec5f0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardizing the country names \n",
    "de_clean = standardize_country_columns(de_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecd6de52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== GERMANY =====\n",
      "\n",
      "Column: In which country are you located?\n",
      "Before: ['Germany', 'Germany ', 'Netherlands', 'Netherlands ', 'Netherworld ', 'Singapore', 'The Netherlands', 'The Netherlands ', 'the Netherlands']\n",
      "After:  ['Germany', 'Netherlands', 'Netherworld', 'Singapore']\n",
      "\n",
      "Column: What is your country of origin?\n",
      "Before: ['Germany', 'Germany ', 'I was Born in Germany, but my family is originally from Sri Lanka.', 'Portugal', 'South Africa ']\n",
      "After:  ['Germany', 'I was Born in Germany, but my family is originally from Sri Lanka.', 'Portugal', 'South Africa']\n",
      "\n",
      "Column: Which description fits your parents' country of origin the best?\n",
      "Before: ['Both parents are born and brought up in the Germany', 'Both parents are from outside the EU', 'Both parents are from the EU', 'One parent is from the EU and one parent is outside of the EU']\n",
      "After:  ['Both parents are born and brought up in the Germany', 'Both parents are from outside the EU', 'Both parents are from the EU', 'One parent is from the EU and one parent is outside of the EU']\n"
     ]
    }
   ],
   "source": [
    "# Showing before/after\n",
    "show_before_after_uniques(de_raw, de_clean, \"GERMANY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4654d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: germanydataset_clean.csv\n"
     ]
    }
   ],
   "source": [
    "#saving the cleaned file\n",
    "de_clean.to_csv(\"germanydataset_clean.csv\", index=False)\n",
    "print(\"\\nSaved: germanydataset_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fc4dd",
   "metadata": {},
   "source": [
    "**Merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5cb313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "841c7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    DATA_PATH / \"spain1dataset_clean.csv\",\n",
    "    DATA_PATH / \"spain2dataset_clean.csv\", #all the four cleaned files in one\n",
    "    DATA_PATH / \"greekdataset_clean.csv\",\n",
    "    DATA_PATH / \"germanydataset_clean.csv\"\n",
    "]\n",
    "\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cb6edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting in a list\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b05cd29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1 columns (spain1dataset_clean.csv):\n",
      "['ID', 'Start time', 'Completion time', 'Email', 'Name', 'Last modified time', 'Please share your email address', 'In which country are you located?', 'What is your country of origin?', \"Which description fits your parents' country of origin the best?\", \"What's your highest/current level of education?\", 'How many languages do you speak?', 'Which languages do you use most online? (select all that applies)', 'What age group are you in?', 'What is your gender?', 'I use social media', 'I think social media is fair', 'I see repeated topics on my feed', 'I see different opinions on the same topic', 'My feed varies within my social circle', \"I often notice that someone didn't know about a trend, which I thought everybody had seen\", 'It is harder for me to take part in a discussion regarding a topic when I have not seen the topic on my feed yet', \"I notice that people mostly agree with what's trending, they rarely add their own personal views - add happens to options\", 'A topic/trend usually stays on my feed for ...', 'When I see a post and open the comments, the top comments reflect what I am already thinking about', 'I scroll through the comments to see if someone has mentioned what I am thinking about', 'I notice a lot of agreement with the content in the comments', 'I tend to comment on content I disagree with', 'I often see new ideas and topics on my feed', 'When I see a new topic on my feed, I tend to scroll away', 'My feed does not show information that others could be seeing', 'I feel like my content gets the same number of views as content from others', 'I feel like my content gets the same number of views as content from others with a different background  (e.g., race, gender, age)\\xa0than mine', 'I think content from certain groups of people is prioritized over other groups', 'I am informed that my feed is shaped by personal information like my age, gender or location - transparency', 'I would feel comfortable swapping feeds with someone from a different background than mine (e.g., age, race, beliefs)', 'If everyone got my feed, I think some people might be shocked by the content they see', 'I would be okay seeing less of my favorite type of content if it meant more equal exposure for everyone', \"If I had to exchange feeds with someone really different from me, I don't think I would like what I would see\", 'When I post about topics like politics or social issues, it feels like my voice can be seen and heard', 'I have seen political content that felt one-sided or biased', 'I feel like the algorithm shapes what political topics I get to see', 'I rarely see posts that challenge my own political views unless I search for them', \"I've seen creators mention that their political-related content was shadowbanned\", 'I feel I am in control of my feed', 'I can influence the type of content I get on my feed', 'The algorithm decides what I watch', 'I scroll through recommendations', \"I end up watching videos I didn't intend to watch\", 'Scrolling feels like a habit rather than a conscious choice', 'I sometimes spend more time scrolling than I had planned', 'I feel like my feed shows me a good mix of topics to stay informed (e.g., news, social issues, or different opinons)', 'I believe that the algorithm hides certain social or political views', 'I feel like I have a fair chance to be seen/heard', 'I trust the algorithm to recommend me content fairly', 'What matters most to you? (1 being the most important and the last number being the least important)', 'I think social media is fair2']\n",
      "\n",
      "Dataset 2 columns (spain2dataset_clean.csv):\n",
      "['Id', 'Start time', 'Completion time', 'Email', 'Name', 'Please share your email address', 'In which country are you located?', 'What is your country of origin?', \"Which description fits your parents' country of origin the best?\", \"What's your highest/current level of education?\", 'How many languages do you speak?', 'Which languages do you use most online? (select all that applies)', 'What age group are you in?', 'What is your gender?', 'I use social media', 'I think social media is fair', 'I see repeated topics on my feed', 'I see different opinions on the same topic', 'My feed varies within my social circle', \"I often notice that someone didn't know about a trend, which I thought everybody had seen\", 'It is harder for me to take part in a discussion regarding a topic when I have not seen the topic on my feed yet', \"I notice that people mostly agree with what's trending, they rarely add their own personal views - add happens to options\", 'A topic/trend usually stays on my feed for ...', 'When I see a post and open the comments, the top comments reflect what I am already thinking about', 'I scroll through the comments to see if someone has mentioned what I am thinking about', 'I notice a lot of agreement with the content in the comments', 'I tend to comment on content I disagree with', 'I often see new ideas and topics on my feed', 'When I see a new topic on my feed, I tend to scroll away', 'My feed does not show information that others could be seeing', 'I feel like my content gets the same number of views as content from others', 'I feel like my content gets the same number of views as content from others with a different background  (e.g., race, gender, age)\\xa0than mine', 'I think content from certain groups of people is prioritized over other groups', 'I am informed that my feed is shaped by personal information like my age, gender or location - transparency', 'I would feel comfortable swapping feeds with someone from a different background than mine (e.g., age, race, beliefs)', 'If everyone got my feed, I think some people might be shocked by the content they see', 'I would be okay seeing less of my favorite type of content if it meant more equal exposure for everyone', \"If I had to exchange feeds with someone really different from me, I don't think I would like what I would see\", 'When I post about topics like politics or social issues, it feels like my voice can be seen and heard', 'I have seen political content that felt one-sided or biased', 'I feel like the algorithm shapes what political topics I get to see', 'I rarely see posts that challenge my own political views unless I search for them', \"I've seen creators mention that their political-related content was shadowbanned\", 'I feel I am in control of my feed', 'I can influence the type of content I get on my feed', 'The algorithm decides what I watch', 'I scroll through recommendations', \"I end up watching videos I didn't intend to watch\", 'Scrolling feels like a habit rather than a conscious choice', 'I sometimes spend more time scrolling than I had planned', 'I feel like my feed shows me a good mix of topics to stay informed (e.g., news, social issues, or different opinons)', 'I believe that the algorithm hides certain social or political views', 'I feel like I have a fair chance to be seen/heard', 'I trust the algorithm to recommend me content fairly', 'What matters most to you? (1 being the most important and the last number being the least important)', 'I think social media is fair1']\n",
      "\n",
      "Dataset 3 columns (greekdataset_clean.csv):\n",
      "['Id', 'Start time', 'Completion time', 'Email', 'Name', 'Please share your email address', 'In which country are you located?', 'What is your country of origin?', \"Which description fits your parents' country of origin the best?\", \"What's your highest/current level of education?\", 'How many languages do you speak?', 'Which languages do you use most online? (select all that applies)', 'What age group are you in?', 'What is your gender?', 'I use social media', 'I think social media is fair', 'I see repeated topics on my feed', 'I see different opinions on the same topic', 'My feed varies within my social circle', \"I often notice that someone didn't know about a trend, which I thought everybody had seen\", 'It is harder for me to take part in a discussion regarding a topic when I have not seen the topic on my feed yet', \"I notice that people mostly agree with what's trending, they rarely add their own personal views - add happens to options\", 'A topic/trend usually stays on my feed for ...', 'When I see a post and open the comments, the top comments reflect what I am already thinking about', 'I scroll through the comments to see if someone has mentioned what I am thinking about', 'I notice a lot of agreement with the content in the comments', 'I tend to comment on content I disagree with', 'I often see new ideas and topics on my feed', 'When I see a new topic on my feed, I tend to scroll away', 'My feed does not show information that others could be seeing', 'I feel like my content gets the same number of views as content from others', 'I feel like my content gets the same number of views as content from others with a different background  (e.g., race, gender, age)\\xa0than mine', 'I think content from certain groups of people is prioritized over other groups', 'I am informed that my feed is shaped by personal information like my age, gender or location - transparency', 'I would feel comfortable swapping feeds with someone from a different background than mine (e.g., age, race, beliefs)', 'If everyone got my feed, I think some people might be shocked by the content they see', 'I would be okay seeing less of my favorite type of content if it meant more equal exposure for everyone', \"If I had to exchange feeds with someone really different from me, I don't think I would like what I would see\", 'When I post about topics like politics or social issues, it feels like my voice can be seen and heard', 'I have seen political content that felt one-sided or biased', 'I feel like the algorithm shapes what political topics I get to see', 'I rarely see posts that challenge my own political views unless I search for them', \"I've seen creators mention that their political-related content was shadowbanned\", 'I feel I am in control of my feed', 'I can influence the type of content I get on my feed', 'The algorithm decides what I watch', 'I scroll through recommendations', \"I end up watching videos I didn't intend to watch\", 'Scrolling feels like a habit rather than a conscious choice', 'I sometimes spend more time scrolling than I had planned', 'I feel like my feed shows me a good mix of topics to stay informed (e.g., news, social issues, or different opinons)', 'I believe that the algorithm hides certain social or political views', 'I feel like I have a fair chance to be seen/heard', 'I trust the algorithm to recommend me content fairly', 'What matters most to you? (1 being the most important and the last number being the least important)', 'I think social media is fair1']\n",
      "\n",
      "Dataset 4 columns (germanydataset_clean.csv):\n",
      "['Id', 'Start time', 'Completion time', 'Email', 'Name', 'Please share your email address', 'In which country are you located?', 'What is your country of origin?', \"Which description fits your parents' country of origin the best?\", \"What's your highest/current level of education?\", 'How many languages do you speak?', 'Which languages do you use most online? (select all that applies)', 'What age group are you in?', 'What is your gender?', 'I use social media', 'I think social media is fair', 'I see repeated topics on my feed', 'I see different opinions on the same topic', 'My feed varies within my social circle', \"I often notice that someone didn't know about a trend, which I thought everybody had seen\", 'It is harder for me to take part in a discussion regarding a topic when I have not seen the topic on my feed yet', \"I notice that people mostly agree with what's trending, they rarely add their own personal views - add happens to options\", 'A topic/trend usually stays on my feed for ...', 'When I see a post and open the comments, the top comments reflect what I am already thinking about', 'I scroll through the comments to see if someone has mentioned what I am thinking about', 'I notice a lot of agreement with the content in the comments', 'I tend to comment on content I disagree with', 'I often see new ideas and topics on my feed', 'When I see a new topic on my feed, I tend to scroll away', 'My feed does not show information that others could be seeing', 'I feel like my content gets the same number of views as content from others', 'I feel like my content gets the same number of views as content from others with a different background  (e.g., race, gender, age)\\xa0than mine', 'I think content from certain groups of people is prioritized over other groups', 'I am informed that my feed is shaped by personal information like my age, gender or location - transparency', 'I would feel comfortable swapping feeds with someone from a different background than mine (e.g., age, race, beliefs)', 'If everyone got my feed, I think some people might be shocked by the content they see', 'I would be okay seeing less of my favorite type of content if it meant more equal exposure for everyone', \"If I had to exchange feeds with someone really different from me, I don't think I would like what I would see\", 'When I post about topics like politics or social issues, it feels like my voice can be seen and heard', 'I have seen political content that felt one-sided or biased', 'I feel like the algorithm shapes what political topics I get to see', 'I rarely see posts that challenge my own political views unless I search for them', \"I've seen creators mention that their political-related content was shadowbanned\", 'I feel I am in control of my feed', 'I can influence the type of content I get on my feed', 'The algorithm decides what I watch', 'I scroll through recommendations', \"I end up watching videos I didn't intend to watch\", 'Scrolling feels like a habit rather than a conscious choice', 'I sometimes spend more time scrolling than I had planned', 'I feel like my feed shows me a good mix of topics to stay informed (e.g., news, social issues, or different opinons)', 'I believe that the algorithm hides certain social or political views', 'I feel like I have a fair chance to be seen/heard', 'I trust the algorithm to recommend me content fairly', 'What matters most to you? (1 being the most important and the last number being the least important)', 'I think social media is fair1']\n"
     ]
    }
   ],
   "source": [
    "# Before merging, I need to check if all files have the same columns\n",
    "# This prevents alignment issues later.\n",
    "for i, df in enumerate(dfs):\n",
    "    print(f\"\\nDataset {i+1} columns ({files[i].name}):\")\n",
    "    print(list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7506ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all column names match, then this code will merge them by stacking rows on top of each other.\n",
    "# pd.concat is the easiest way to do this.\n",
    "combined = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0a2c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the final merged file.\n",
    "combined.to_csv(\"combined_clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "967aea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: combined_clean_dataset.csv\n",
      "Final shape: (81, 59)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaved: combined_clean_dataset.csv\")\n",
    "print(\"Final shape:\", combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423eed3",
   "metadata": {},
   "source": [
    "All three country datasets are cleaned and merged into one combined file. Country names, formatting issues, and inconsistencies are corrected so that all data aligns properly. The final merged dataset is complete for statistical analysis in the next steps of the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
